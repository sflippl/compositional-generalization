filter(abs(A_vs_C)>= 0.0025, abs(a_vs_c)>=0.0025)
df_c_b <-
df_c %>%
filter(abs(A_vs_C)<= 0.0025, abs(a_vs_c)<=0.0025)
fig_b <-
bind_rows(
df_c[sample.int(nrow(df_c_a), size=1000),],
df_c[sample.int(nrow(df_c_b), size=1000),]
) %>%
ggplot(aes(A_vs_C, a_vs_c, color=factor(sign(foutput)))) +
geom_point(alpha=1, shape='.') +
coord_equal(xlim = c(-0.01, 0.01), ylim=c(-0.01, 0.01)) +
scale_color_manual(values = c(`-1` = scales::muted('red'), `1`=scales::muted('blue')), labels = c('Neg.', 'Pos.')) +
my_theme +
labs(x=NULL, y=NULL, color='Unit sign') +
guides(colour = guide_legend(override.aes= list(alpha = 1))) +
scale_y_continuous(breaks=c(-0.01, 0.01)) +
scale_x_continuous(breaks=c(-0.01, 0.01)) +
geom_label(inherit.aes=FALSE, data = tibble(x = c(1,1,-1,-1), y=c(1,-1,1,-1), text=c('AB', 'AE', 'DB', 'DE')), mapping = aes(x=0.0075*x, y=0.0075*y, label=text), size=1.5, label.padding = unit(0.1, "lines"))
fig_b
df_2_comp <-
df_2_weights %>%
filter(regime=='rich', feature != 'output') %>%
mutate(component = if_else(as.integer(feature)<=3, '1', '2')) %>%
inner_join(
df_2_weights %>%
filter(regime == 'rich', feature == 'output') %>%
select(-feature) %>%
rename(output = weight)
) %>%
mutate(weight = output*weight) %>%
select(-output)
df_2_comp <-
inner_join(
df_2_comp %>% mutate(feat_1 = as.integer(feature) %% 4, weight_2=weight) %>% select(-feature,-weight),
df_2_comp %>% mutate(feat_2 = as.integer(feature) %% 4, weight_1=weight) %>% select(-feature, -weight)
) %>%
mutate(
type = if_else((feat_1<=1)==(feat_2<=1), 'Equivalent', 'Not equivalent')
)
df_2_comp_a <-
df_2_comp %>% filter(abs(weight_1)>= 0.001, abs(weight_2)>=0.001)
df_2_comp_b <-
df_2_comp %>% filter(abs(weight_1)<= 0.001, abs(weight_2)<=0.001)
df_2_comp <-
bind_rows(
df_2_comp_a[sample.int(nrow(df_2_comp_a), size=1000),],
df_2_comp_b[sample.int(nrow(df_2_comp_b), size=1000),]
)
fig_c <-
df_2_comp %>%
ggplot(aes(weight_1, weight_2, color=type)) +
geom_point(shape='.') +
my_theme +
coord_equal(xlim=c(-0.006, 0.006), ylim=c(-0.006, 0.006)) +
scale_color_manual(values = c(Equivalent = 'purple', `Not equivalent` = 'darkgreen'), labels = c('Eq.', 'Not eq.')) +
guides(color = guide_legend(override.aes= list(alpha = 1))) +
labs(x=NULL, y=NULL, color=NULL) +
scale_x_continuous(breaks=c(-0.005, 0.005)) +
scale_y_continuous(breaks=c(-0.005, 0.005))
fig_c
metrics_mnist <-
read_csv('../collated/24_te_mnist/metrics.csv') %>%
filter(!is.na(val_loss)) %>%
mutate(
train_items = if_else(task.train_items == '[1, 1]', '1', '4')
) %>%
select(-step, -train_loss, -task.train_items) %>%
pivot_longer(cols=starts_with('task')) %>%
separate(col=name, into=c(NA, 'task_split', NA, NA, 'embedding_split', 'metric'), sep="[(--),=,/]")
se <- function(x) sd(x)/sqrt(length(x))
fig_d <-
metrics_mnist %>%
filter(epoch == 150, train_items=='4', model.trainer_config.criterion=='crossentropy', metric=='binary_accuracy', embedding_split %in% c('val_2', 'train')) %>%
mutate(
generalization = case_when(
embedding_split == 'train' ~ 'Training set',
task_split == 'train' ~ 'In-distribution',
task_split == 'test' ~ 'Compositional'
) %>% factor(levels = c('Training set', 'In-distribution', 'Compositional'))
) %>%
ggplot(aes(embedding.input_generator.distance, value, color=generalization, group=generalization)) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=.25) +
my_theme +
labs(y = 'Acc.', x = 'Dist.', color='Split', linetype=NULL) +
scale_color_manual(
values = c('black', 'blue', 'orange')
) +
guides(linetype=guide_none()) +
scale_x_continuous(breaks = c(0, 20)) +
scale_y_continuous(breaks = c(0.5, 1), limits = c(NA, 1))
fig_d
fig <-
fig_a + fig_b + fig_c + fig_d + plot_layout(nrow=1) + plot_annotation(tag_levels = 'a')
fig & theme(legend.position='top')
ggsave('../figures/neurips/neurips-4.pdf', width = width*2/3, height = 0.3*width, units = 'cm')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(patchwork)
library(latex2exp)
library(magrittr)
my_theme <-
ggplot2::theme_classic() +
ggplot2::theme(
title = ggplot2::element_text(size = 8),
text = ggplot2::element_text(size = 7),
axis.text = ggplot2::element_text(size = 7),
legend.text = ggplot2::element_text(size = 7),
plot.tag = ggplot2::element_text(face = 'bold', size = 8),
strip.text = ggplot2::element_text(size = 7),
strip.background = element_blank(),
legend.key.size = unit(6, 'pt'),
panel.background = element_blank(),
plot.margin = unit(c(0,0,0,0), 'pt'),
plot.background=element_blank()
)
width <- 13.968
linewidth <- 0.25
values_cifar <-
bind_rows(
read_csv('../collated/C18_addition_resnet/labels.csv') %>%
filter(epoch == 100) %>%
mutate(
task = task.training_comps,
network = 'ResNet on CIFAR'
),
read_csv('../collated/C16_vit_cifar_improved/labels.csv') %>%
filter((epoch == 179)|((epoch==99)&(task.training_comps=='[[4], [4]]'))) %>%
mutate(
task = task.training_comps,
network = 'ViT on CIFAR'
),
) %>%
mutate(
task = case_when(
task.training_comps == '[[0, 8], [0, 8]]' ~ 'Interpolation',
task.training_comps == '[[4], [4]]' ~ 'Extrapolation',
task.training_comps == '[[0], [0]]' ~ 'Asymmetric\nextrapolation'
) %>%
factor(
levels = c('Extrapolation', 'Asymmetric\nextrapolation', 'Interpolation')
)
)
values_cifar <-
values_cifar %>%
filter(if_else(comp_0=='all', comp_1!='all', comp_1=='all'), epoch!=0) %>%
inner_join(
values_cifar %>%
filter(comp_0=='all', comp_1=='all') %>%
select(-comp_0, -comp_1) %>%
rename(intercept=value)
) %>%
mutate(value = value + intercept/2) %>%
mutate(
item = if_else(comp_0=='all', comp_1, comp_0) %>%
as.integer(),
component = if_else(comp_0=='all', '2', '1')
)
values_mnist <-
read_csv('../collated/19_addition_mnist/labels.csv') %>%
filter(epoch != 0) %>%
mutate(
task = if_else(
task.instances_seed != 'None',
paste0('dispersed (', task.instances_seed, ')'),
task.training_comps
),
task_type = if_else(
task.instances_seed != 'None', 'dispersed', 'comps'
)
)
values_mnist <-
values_mnist %>%
filter(if_else(comp_0=='all', comp_1!='all', comp_1=='all'), epoch!=0) %>%
inner_join(
values_mnist %>%
filter(comp_0=='all', comp_1=='all') %>%
select(-comp_0, -comp_1) %>%
rename(intercept=value)
) %>%
mutate(value = value + intercept/2) %>%
mutate(
item = if_else(comp_0=='all', comp_1, comp_0) %>%
as.integer(),
component = if_else(comp_0=='all', '2', '1')
)
fig_a <-
bind_rows(
values_mnist %>% filter(embedding.input_generator.distance == 0) %>%
filter(task == '[[4], [4]]') %>%
mutate(network = 'ConvNet on MNIST'),
values_cifar %>% filter(task == 'Extrapolation')
) %>%
ggplot(aes(item-4, value, color=network, group=network, linetype=network)) +
geom_abline(slope=1, color='black', linetype='11', size=0.25) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend=FALSE, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=0.25) +
my_theme +
coord_fixed() +
labs(x = 'Item', y = 'Value', linetype = NULL, color = NULL) +
scale_x_continuous(breaks = c(-4, 0, 4), labels = c('[-4]', '[0]', '[4]')) +
scale_y_continuous(breaks = c(-4, 0, 4), limits = c(-4, 4)) +
scale_color_brewer(palette = 'Dark2') +
scale_linetype_manual(values = c('solid', '21', '21'))
fig_a
similarity_mnist <-
read_csv('../collated/19_addition_mnist/similarity_features.csv', guess_max = 1e5) %>%
filter(layer == 11) %>%
#filter(layer %in% c(0, 16, 18, 7, 9, 12, 14)) %>%
separate(col = spec0, into=c(NA, 'spec0_1', 'spec0_2')) %>%
separate(col = spec1, into=c(NA, 'spec1_1', 'spec1_2')) %>%
mutate(
training = if_else(epoch==0, 'before', 'after'),
trial_type = case_when(
(spec0_1==spec1_1)&(spec0_2==spec1_2)~'identical',
(spec0_1==spec1_1)|(spec0_2==spec1_2)~'overlapping',
TRUE~'distinct'
)
) %>%
group_by(spec0_1, spec1_1, spec0_2, spec1_2, trial_type, embedding.input_generator.distance, embedding.input_generator.seed, layer, training) %>%
summarise(array = mean(array))
similarity_mnist <-
similarity_mnist %>%
inner_join(
similarity_mnist %>%
filter(trial_type%in% c('identical', 'distinct')) %>%
group_by(embedding.input_generator.distance, embedding.input_generator.seed, layer, training, trial_type) %>%
summarise(array = mean(array)) %>%
pivot_wider(names_from = 'trial_type', values_from = 'array')
)
se <- function(x) sd(x)/sqrt(length(x))
fig_b <-
similarity_mnist %>%
filter(layer %in% c(11, 15, 17, 9, 1), trial_type=='overlapping', training=='before', layer==11) %>%
#group_by(spec0_1, spec0_2, spec1_1, spec1_2, layer, training, trial_type, embedding.input_generator.distance) %>%
#summarise(array = mean(array), distinct = mean(distinct), identical = mean(identical)) %>%
ggplot(aes(embedding.input_generator.distance, (array-distinct)/(identical-distinct))) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend=FALSE, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
#stat_summary() +
labs(x = 'Dist.', y = 'Sal(1,2)') +
stat_summary(geom='line', size=.25) +
my_theme +
scale_y_continuous(n.breaks = 2) +
scale_x_continuous(breaks = c(0, 20))
fig_b
fig_c <-
values_mnist %>%
filter(task == '[[4], [4]]') %>%
mutate(
distance = as.double(embedding.input_generator.distance)
) %>%
ggplot(aes(item-4, value, color=distance, group=embedding.input_generator.distance)) +
geom_abline(slope=1, color='black', linetype='11', size=0.25) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x), show.legend=FALSE) +
stat_summary(geom='line', size=.25) +
my_theme +
coord_fixed() +
labs(x = 'Item', y = 'Value', color = 'Dist.') +
scale_color_viridis_c(breaks = c(0, 20)) +
scale_x_continuous(breaks = c(-4, 0, 4), labels = c('[-4]', '[0]', '[4]')) +
scale_y_continuous(breaks = c(-4, 0, 4), limits = c(-4, 4)) +
theme(legend.position = c(0.2, 0.8))
fig_c
metrics_mnist <- read_csv('../collated/22_cdm_mnist/metrics.csv') %>%
mutate(
leftout_conjunctions = case_when(
task.leftout_conjunctions == "[{1: [0, 1, 2], 2: [3, 4, 5]}]" ~ '3',
task.leftout_conjunctions == "[{1: [0, 1], 2: [3, 4]}]" ~ '2',
task.leftout_conjunctions == "[{1: [0], 2: [3]}]" ~ '1'
)
) %>%
select(-train_loss, -step, -task.leftout_conjunctions) %>%
filter(!is.na(val_loss)) %>%
pivot_longer(cols=starts_with('task')) %>%
separate(col=name, into=c(NA, 'task_split', NA, NA, 'embedding_split', 'metric'), sep="[(--),=,/]")
last_epoch_mnist <-
metrics_mnist %>%
group_by(leftout_conjunctions, task_split, embedding_split, metric, model.trainer_config.criterion, embedding.input_generator.seed, embedding.input_generator.distance) %>%
summarise(epoch = max(epoch)) %>%
filter(epoch>0)
fig_d <-
metrics_mnist %>%
inner_join(last_epoch_mnist) %>%
filter(metric == 'binary_accuracy', model.trainer_config.criterion=='crossentropy', embedding_split == 'val_2', task_split=='test') %>%
ggplot(aes(embedding.input_generator.distance, value, color=leftout_conjunctions, group=leftout_conjunctions)) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend=FALSE, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=.25) +
my_theme +
scale_y_continuous(limits = c(0,1), breaks = c(0, 0.5, 1)) +
scale_x_continuous(breaks = c(0, 20)) +
scale_color_manual(values = c(`3` = '#11C638', `2` = '#83D38A', `1` = '#C4DEC6'), labels = c('CDM-3', 'CDM-2', 'CDM-1')) +
labs(x = 'Dist.', y = 'Accuracy', color = 'Task')
fig_d
values <- read_csv('../collated/22_cdm_mnist/labels.csv') %>%
filter(embedding.input_generator.distance == 20) %>%
mutate(
leftout_conjunctions = case_when(
task.leftout_conjunctions == "[{1: [0, 1, 2], 2: [3, 4, 5]}]" ~ '3',
task.leftout_conjunctions == "[{1: [0, 1], 2: [3, 4]}]" ~ '2',
task.leftout_conjunctions == "[{1: [0], 2: [3]}]" ~ '1'
)
) %>%
mutate(
conjunction_type = case_when(
(comp_0 == 'all') & (comp_1 == 'all') & (comp_2 == 'all') ~ 'intercept',
(comp_1 == 'all') & (comp_2 == 'all') ~ 'context only',
((comp_0 == '0') & (comp_1 == 'all')) | ((comp_0 == '1') & (comp_2 == 'all')) ~ 'wrong conj',
((comp_0 == '1') & (comp_1 == 'all')) | ((comp_0 == '0') & (comp_2 == 'all')) ~ 'right conj',
(comp_0 == 'all') & ((comp_1=='all') | (comp_2=='all')) ~ 'sensory feature',
(comp_0 == 'all') ~ 'sensory feature',
TRUE ~ 'memorization'
)
)
values <-
values %>%
filter(model.trainer_config.criterion == 'crossentropy') %>%
group_by(comp_0, comp_1, comp_2, leftout_conjunctions, conjunction_type) %>%
summarise(value = mean(value)) %>%
mutate(
conjunction_type = conjunction_type %>%
factor(levels = c('right conj', 'wrong conj', 'sensory feature', 'context only', 'memorization')) %>%
fct_rev()
) %>%
filter(conjunction_type != 'intercept') %>%
group_by(conjunction_type, leftout_conjunctions) %>%
summarise(value = mean(abs(value)))
values <-
values %>%
inner_join(
values %>%
group_by(leftout_conjunctions) %>%
summarise(total = sum(value))
) %>%
mutate(value = value/total)
df <- bind_rows(
read_csv('../collated/C15_cdm_cifar_resnet_improved/labels.csv', guess_max = 1e5) %>%
filter(epoch==99) %>%
mutate(network = 'ResNet on\nCIFAR'),
read_csv('../collated/C19_cdm_cifar_vit/labels.csv') %>%
mutate(network = 'ViT on\nCIFAR') %>%
filter(epoch == 200)
) %>%
mutate(
leftout_conjunctions = case_when(
task.leftout_conjunctions == "[{1: [0, 1, 2], 2: [3, 4, 5]}]" ~ '3',
task.leftout_conjunctions == "[{1: [0, 1], 2: [3, 4]}]" ~ '2',
task.leftout_conjunctions == "[{1: [0], 2: [3]}]" ~ '1'
)
) %>%
mutate(
conjunction_type = case_when(
(comp_0 == 'all') & (comp_1 == 'all') & (comp_2 == 'all') ~ 'intercept',
(comp_1 == 'all') & (comp_2 == 'all') ~ 'context only',
((comp_0 == '0') & (comp_1 == 'all')) | ((comp_0 == '1') & (comp_2 == 'all')) ~ 'wrong conj',
((comp_0 == '1') & (comp_1 == 'all')) | ((comp_0 == '0') & (comp_2 == 'all')) ~ 'right conj',
(comp_0 == 'all') & ((comp_1=='all') | (comp_2=='all')) ~ 'sensory feature',
(comp_0 == 'all') ~ 'sensory feature',
TRUE ~ 'memorization'
)
) %>%
group_by(comp_0, comp_1, comp_2, leftout_conjunctions, conjunction_type, network) %>%
summarise(value = mean((value))) %>%
group_by(leftout_conjunctions, conjunction_type, network) %>%
summarise(value = mean(abs(value)))
df <-
df %>%
inner_join(
df %>%
group_by(leftout_conjunctions, network) %>%
summarise(total = sum(value))
) %>%
mutate(value = value/total)
fig_e <-
bind_rows(
values %>% mutate(network = 'ConvNet on\nMNIST'),
df %>% filter(conjunction_type != 'intercept')
) %>%
ggplot(aes(conjunction_type, abs(value), fill=leftout_conjunctions)) +
stat_summary(geom='bar', position='dodge') +
coord_flip() +
scale_x_discrete(breaks = c('right conj', 'wrong conj', 'sensory feature', 'context only', 'memorization'),
labels = c('Right conj.', 'Wrong conj.', 'Sensory feat.', 'Context only', 'Memorization')) +
#scale_fill_manual(values = c('darkgreen', 'orange')) +
scale_fill_manual(values = c(`3` = '#11C638', `2` = '#83D38A', `1` = '#C4DEC6'), breaks = c(3, 2, 1), labels = c('CDM-3', 'CDM-2', 'CDM-1')) +
labs(x = 'Conj. type', y = 'Rel. magnitude', fill='Task variant') +
scale_y_continuous(breaks = c(0, 0.5)) +
facet_wrap(~network, nrow=1) +
my_theme
fig_e
metrics_mnist <-
read_csv('../collated/24_te_mnist/metrics.csv') %>%
filter(!is.na(val_loss)) %>%
mutate(
train_items = if_else(task.train_items == '[1, 1]', '1', '4')
) %>%
select(-step, -train_loss, -task.train_items) %>%
pivot_longer(cols=starts_with('task')) %>%
separate(col=name, into=c(NA, 'task_split', NA, NA, 'embedding_split', 'metric'), sep="[(--),=,/]")
se <- function(x) sd(x)/sqrt(length(x))
fig_f <-
metrics_mnist %>%
filter(epoch == 150, model.trainer_config.criterion=='crossentropy', metric=='binary_accuracy', embedding_split %in% c('val_2', 'train')) %>%
mutate(
generalization = case_when(
embedding_split == 'train' ~ 'Training set',
task_split == 'train' ~ 'In-distribution',
task_split == 'test' ~ 'Compositional'
) %>% factor(levels = c('Training set', 'In-distribution', 'Compositional'))
) %>%
ggplot(aes(embedding.input_generator.distance, value, color=generalization, group=generalization)) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=.25) +
my_theme +
labs(y = 'Acc.', x = 'Dist.', color='Split', linetype=NULL) +
scale_color_manual(
values = c('black', 'blue', 'orange')
) +
guides(linetype=guide_none()) +
scale_x_continuous(breaks = c(0, 20)) +
scale_y_continuous(breaks = c(0.5, 1), limits = c(NA, 1))
fig_f
fig <- (fig_a + fig_b + fig_c + fig_e + fig_f) + plot_layout(nrow=1, widths=c(1,1,1,3,1))
fig <- fig + plot_annotation(tag_levels = 'a')
fig & theme(legend.position = 'top')
ggsave('../figures/neurips/neurips-5.pdf', width = width, height = 0.35*width, units = 'cm')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(patchwork)
library(latex2exp)
library(reticulate)
library(magrittr)
my_theme <-
ggplot2::theme_classic() +
ggplot2::theme(
title = ggplot2::element_text(size = 8),
text = ggplot2::element_text(size = 7),
axis.text = ggplot2::element_text(size = 7),
legend.text = ggplot2::element_text(size = 7),
plot.tag = ggplot2::element_text(face = 'bold', size = 8),
strip.text = ggplot2::element_text(size = 7),
strip.background = element_blank(),
legend.key.size = unit(6, 'pt'),
panel.background = element_blank(),
plot.margin = unit(c(0,0,0,0), 'pt'),
plot.background=element_blank()
)
width <- 13.968
linewidth <- 0.25
values_dispersed <- read_csv('../collated/D1_addition_dispersed/labels.csv') %>%
mutate(
sal=`sim_(1, 0)`
)
values_dispersed <-
values_dispersed %>%
filter(if_else(comp_0=='all', comp_1!='all', comp_1=='all')) %>%
inner_join(
values_dispersed %>%
filter(comp_0=='all', comp_1=='all') %>%
select(-comp_0, -comp_1) %>%
rename(intercept=value)
) %>%
mutate(value = value + intercept/2) %>%
mutate(
item = if_else(comp_0=='all', comp_1, comp_0) %>%
as.integer(),
component = if_else(comp_0=='all', '2', '1')
)
fig_k_a <-
values_dispersed %>%
filter(task.instances_seed<=4) %>%
filter(sal %in% c(0.3, 0.4, 0.45, 0.49, 0.5)) %>%
ggplot(aes(item-4, value, color=sal, linetype=component, group=paste(sal, component))) +
geom_abline(slope=1, color='grey', linetype='dashed') +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend = FALSE,
fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=linewidth) +
my_theme +
coord_fixed() +
facet_wrap(~task.instances_seed, nrow=1) +
labs(x = 'Item', y = 'Value', linetype = 'Comp.', color = 'Sal_2(1)') +
scale_color_viridis_c(breaks = c(0.3, 0.5)) +
scale_y_continuous(breaks = c(-4, 0, 4), limits = c(-4, 4))
fig_k_a
fig_b <-
values_dispersed %>%
filter(sal %in% c(0.3, 0.4, 0.45, 0.49, 0.5)) %>%
ggplot(aes(item-4, value, color=sal, group=sal)) +
geom_abline(slope=1, color='grey', linetype='dashed') +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend = FALSE,
fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line', size=linewidth) +
my_theme +
coord_fixed() +
labs(x = 'Item', y = 'Value', color = 'Sal_2(1)') +
scale_color_viridis_c(breaks = c(0.3, 0.5)) +
scale_y_continuous(breaks = c(-4, 0, 4), limits = c(-4, 4))
fig_b
fig_k_c <-
read_csv('../collated/D1_addition_dispersed/metrics.csv') %>%
filter(split == 'task=test', metric == 'mse') %>%
mutate(
sal=`sim_(1, 0)`
) %>%
ggplot(aes(sal, value)) +
stat_summary(geom='ribbon', color=NA, fill='grey20', alpha=0.2, show.legend = FALSE,
fun.min=function(x)mean(x)-2*se(x), fun.max=function(x)mean(x)+2*se(x)) +
stat_summary(geom='line') +
labs(y = 'Gen. loss', x = 'Sal_2(1)') +
my_theme
fig_k_c
reticulate::repl_python()
